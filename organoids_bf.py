# -*- coding: utf-8 -*-
"""Organoids_BF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zzAyokxc-7uNBf-siI-Q60s4YO-Vk9wn
"""

!pip install imagecodecs

"""This cell processes microscopy images to detect droplets using the Hough Circle Transform, calculate cell viability based on green fluorescence, and crop each valid droplet to 128Ã—128 pixels. Droplets with less than 0.1% dead cells are filtered out. The cropped images and their corresponding viability percentages are saved for model training."""

import cv2
import numpy as np
import os
import pandas as pd
from tqdm import tqdm

# ============================
# USER SETTINGS
# ============================
input_folder = "/content/drive/MyDrive/Colab Notebooks/Input 1"         # folder containing input .tif, .png, etc.
output_crop_dir = "Cropped_Droplets"        # output folder for cropped droplets
CROP_SIZE = 128                              # size for each cropped droplet
os.makedirs(output_crop_dir, exist_ok=True)

# ============================
# HELPER FUNCTION
# ============================
def crop_droplet_region(image, x, y, r, size=CROP_SIZE):
    h, w = image.shape[:2]
    left = max(x - r, 0)
    top = max(y - r, 0)
    right = min(x + r, w)
    bottom = min(y + r, h)

    # Prevent invalid crops
    if right <= left or bottom <= top:
        return None

    crop = image[top:bottom, left:right]
    if crop.size == 0:
        return None

    crop_resized = cv2.resize(crop, (size, size), interpolation=cv2.INTER_AREA)
    return crop_resized

# ============================
# MAIN LOOP OVER IMAGES
# ============================
all_results = []

for filename in tqdm(os.listdir(input_folder), desc="Processing images"):
    if not filename.lower().endswith((".tif", ".tiff", ".png", ".jpg", ".jpeg")):
        continue

    image_path = os.path.join(input_folder, filename)
    img_bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)
    if img_bgr is None:
        print(f"âŒ Could not load {filename}, skipping...")
        continue

    # --- Grayscale + invert + blur ---
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.bitwise_not(gray)
    gray_blur = cv2.medianBlur(gray, 5)

    # --- Detect droplets using HoughCircles ---
    circles = cv2.HoughCircles(
        gray_blur,
        cv2.HOUGH_GRADIENT,
        dp=1.2,
        minDist=20,
        param1=50,
        param2=50,
        minRadius=50,
        maxRadius=65
    )

    if circles is None:
        continue

    circles = np.uint16(np.around(circles[0]))

    # --- Create cell masks ---
    gray_for_bf = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    bf_blur = cv2.GaussianBlur(gray_for_bf, (5, 5), 0)
    _, bf_cells_mask = cv2.threshold(bf_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    lower_green = np.array([35, 50, 50])
    upper_green = np.array([85, 255, 255])
    green_mask = cv2.inRange(hsv, lower_green, upper_green)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    bf_cells_mask = cv2.morphologyEx(bf_cells_mask, cv2.MORPH_CLOSE, kernel)
    green_mask    = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)

    # --- Process each droplet ---
    for i, (x, y, r) in enumerate(circles, start=1):
        x, y, r = int(x), int(y), int(r)

        droplet_mask = np.zeros_like(bf_cells_mask)
        cv2.circle(droplet_mask, (x, y), r, 255, -1)

        bf_in_droplet = cv2.bitwise_and(bf_cells_mask, droplet_mask)
        green_in_droplet = cv2.bitwise_and(green_mask, droplet_mask)

        total_area = np.count_nonzero(bf_in_droplet)
        dead_area = np.count_nonzero(green_in_droplet)

        if total_area == 0 or dead_area == 0:
            continue

        percent_dead = (dead_area / total_area) * 100.0

        # âŒ Skip droplets with very low dead signal
        if percent_dead < 0.1:
            continue

        crop = crop_droplet_region(img_bgr, x, y, r)
        if crop is not None:
            crop_filename = f"{os.path.splitext(filename)[0]}_droplet_{i:03d}.png"
            cv2.imwrite(os.path.join(output_crop_dir, crop_filename), crop)

            all_results.append({
                "filename": crop_filename,
                "Percent_Dead": percent_dead
            })

# ============================
# SAVE CSV WITH LABELS
# ============================
df = pd.DataFrame(all_results)
csv_path = os.path.join(output_crop_dir, "droplet_viability_labels.csv")
df.to_csv(csv_path, index=False)

print(f"âœ… Done! {len(df)} droplets saved with labels to:\n  {csv_path}")

"""Code to Download the cropped images and csv file"""

import shutil
from google.colab import files

# Step 1: Zip the entire Cropped_Droplets folder
shutil.make_archive("Cropped_Droplets", 'zip', "Cropped_Droplets")

# Step 2: Download the zip file
files.download("Cropped_Droplets.zip")

"""This cell defines and trains a convolutional neural network (CNN) regression model to predict the percent of dead cells in droplet images. The dataset is split into training and validation sets (80/20), and images are resized to 128Ã—128 pixels. The model consists of two convolutional layers followed by fully connected layers, and it is trained using mean squared error (MSE) loss over 100 epochs. A plot is generated to visualize training and validation loss across epochs."""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
from PIL import Image
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt

# ============================
# Dataset Definition
# ============================
class DropletDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.labels_df = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx):
        img_path = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0])
        image = Image.open(img_path).convert("L")
        if self.transform:
            image = self.transform(image)

        raw_percent_dead = self.labels_df.iloc[idx, 1]
        label = np.log1p(raw_percent_dead / 100.0)  # log scale normalized value
        return image, torch.tensor(label, dtype=torch.float32)

# ============================
# Transform & Data Loading
# ============================
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

dataset = DropletDataset(
    csv_file="Cropped_Droplets/droplet_viability_labels.csv",
    root_dir="Cropped_Droplets",
    transform=transform
)

train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
generator = torch.Generator().manual_seed(42)
train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

# ============================
# CNN Model
# ============================
class CNNRegressor(nn.Module):
    def __init__(self):
        super(CNNRegressor, self).__init__()
        self.model = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(32 * 32 * 32, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        return self.model(x).squeeze(1)

# ============================
# Training Setup
# ============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CNNRegressor().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
loss_fn = nn.MSELoss()

train_losses = []
val_losses = []
num_epochs = 100

# ============================
# Training Loop
# ============================
for epoch in range(num_epochs):
    model.train()
    total_loss = 0

    for imgs, labels in train_loader:
        imgs = imgs.to(device)
        labels = labels.to(device)

        preds = model(imgs)
        loss = loss_fn(preds, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_train_loss = total_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    # Validation
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs = imgs.to(device)
            labels = labels.to(device)
            preds = model(imgs)
            loss = loss_fn(preds, labels)
            val_loss += loss.item()

    avg_val_loss = val_loss / len(val_loader)
    val_losses.append(avg_val_loss)

    print(f"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}")

# ============================
# Plot Training Curve
# ============================
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("MSE Loss")
plt.title("Training and Validation Loss")
plt.legend()
plt.grid(True)
plt.show()

# ============================
# Evaluate Predictions (reverse log scale)
# ============================
true_vals = []
pred_vals = []

model.eval()
with torch.no_grad():
    for imgs, labels in val_loader:
        imgs = imgs.to(device)
        preds = model(imgs).cpu().numpy()
        labels = labels.cpu().numpy()

        # Convert both back to original % dead space
        preds_rescaled = np.expm1(preds) * 100
        labels_rescaled = np.expm1(labels) * 100

        pred_vals.extend(preds_rescaled)
        true_vals.extend(labels_rescaled)

# ============================
# Plot Predictions vs Ground Truth
# ============================
plt.figure(figsize=(6,6))
plt.scatter(true_vals, pred_vals, alpha=0.6)
plt.plot([0, max(true_vals)], [0, max(true_vals)], 'r--')
plt.xlabel("True % Dead")
plt.ylabel("Predicted % Dead")
plt.title("Prediction vs. Actual Viability")
plt.grid(True)
plt.show()

# ============================
# Predict on a New Uploaded Droplet Image
# ============================
from PIL import Image

def predict_single_image(image_path, model, transform, device):
    model.eval()
    image = Image.open(image_path).convert("L")
    image = transform(image).unsqueeze(0).to(device)  # add batch dim

    with torch.no_grad():
        pred = model(image).item()

    # Reverse the log1p transformation
    percent_dead = np.expm1(pred) * 100
    return percent_dead

# Example usage:
# Replace this with the actual path of your uploaded image
uploaded_image_path = "/content/example_droplet.png"  # ðŸ” change this after uploading
predicted_percent_dead = predict_single_image(uploaded_image_path, model, transform, device)

print(f"ðŸ§ª Predicted % Dead: {predicted_percent_dead:.2f}%")