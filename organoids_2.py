# -*- coding: utf-8 -*-
"""Organoids_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/117qMx0PilwPdIOugJVWqpxh0A5aHEpEb
"""

!pip install imagecodecs

"""This cell processes microscopy images to detect droplets using the Hough Circle Transform, calculate cell viability based on green fluorescence, and crop each valid droplet to 128×128 pixels. Droplets with less than 0.1% dead cells are filtered out. The cropped images and their corresponding viability percentages are saved for model training."""

import cv2
import numpy as np
import os
import pandas as pd
from tqdm import tqdm

# ============================
# USER SETTINGS
# ============================
input_folder = "/content/drive/MyDrive/Colab Notebooks/Input_final"         # folder containing input .tif, .png, etc.
output_crop_dir = "Cropped_Droplets"        # output folder for cropped droplets
CROP_SIZE = 128                              # size for each cropped droplet
os.makedirs(output_crop_dir, exist_ok=True)

# ============================
# HELPER FUNCTION
# ============================
def crop_droplet_region(image, x, y, r, size=CROP_SIZE):
    h, w = image.shape[:2]
    left = max(x - r, 0)
    top = max(y - r, 0)
    right = min(x + r, w)
    bottom = min(y + r, h)

    # Prevent invalid crops
    if right <= left or bottom <= top:
        return None

    crop = image[top:bottom, left:right]
    if crop.size == 0:
        return None

    crop_resized = cv2.resize(crop, (size, size), interpolation=cv2.INTER_AREA)
    return crop_resized

# ============================
# MAIN LOOP OVER IMAGES
# ============================
all_results = []

for filename in tqdm(os.listdir(input_folder), desc="Processing images"):
    if not filename.lower().endswith((".tif", ".tiff", ".png", ".jpg", ".jpeg")):
        continue

    image_path = os.path.join(input_folder, filename)
    img_bgr = cv2.imread(image_path, cv2.IMREAD_COLOR)
    if img_bgr is None:
        print(f"❌ Could not load {filename}, skipping...")
        continue

    # --- Grayscale + invert + blur ---
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.bitwise_not(gray)
    gray_blur = cv2.medianBlur(gray, 5)

    # --- Detect droplets using HoughCircles ---
    circles = cv2.HoughCircles(
        gray_blur,
        cv2.HOUGH_GRADIENT,
        dp=1.2,
        minDist=20,
        param1=50,
        param2=50,
        minRadius=50,
        maxRadius=65
    )

    if circles is None:
        continue

    circles = np.uint16(np.around(circles[0]))

    # --- Create cell masks ---
    gray_for_bf = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    bf_blur = cv2.GaussianBlur(gray_for_bf, (5, 5), 0)
    _, bf_cells_mask = cv2.threshold(bf_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    lower_green = np.array([35, 50, 50])
    upper_green = np.array([85, 255, 255])
    green_mask = cv2.inRange(hsv, lower_green, upper_green)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    bf_cells_mask = cv2.morphologyEx(bf_cells_mask, cv2.MORPH_CLOSE, kernel)
    green_mask    = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)

    # --- Process each droplet ---
    for i, (x, y, r) in enumerate(circles, start=1):
        x, y, r = int(x), int(y), int(r)

        droplet_mask = np.zeros_like(bf_cells_mask)
        cv2.circle(droplet_mask, (x, y), r, 255, -1)

        bf_in_droplet = cv2.bitwise_and(bf_cells_mask, droplet_mask)
        green_in_droplet = cv2.bitwise_and(green_mask, droplet_mask)

        total_area = np.count_nonzero(bf_in_droplet)
        dead_area = np.count_nonzero(green_in_droplet)

        if total_area == 0 or dead_area == 0:
            continue

        percent_dead = (dead_area / total_area) * 100.0

        # ❌ Skip droplets with very low dead signal
        if percent_dead < 0.1:
            continue

        crop = crop_droplet_region(img_bgr, x, y, r)
        if crop is not None:
            crop_filename = f"{os.path.splitext(filename)[0]}_droplet_{i:03d}.png"
            cv2.imwrite(os.path.join(output_crop_dir, crop_filename), crop)

            all_results.append({
                "filename": crop_filename,
                "Percent_Dead": percent_dead
            })

# ============================
# SAVE CSV WITH LABELS
# ============================
df = pd.DataFrame(all_results)
csv_path = os.path.join(output_crop_dir, "droplet_viability_labels.csv")
df.to_csv(csv_path, index=False)

print(f"✅ Done! {len(df)} droplets saved with labels to:\n  {csv_path}")

"""Code to Download the cropped images and csv file"""

import shutil
from google.colab import files

# Step 1: Zip the entire Cropped_Droplets folder
shutil.make_archive("Cropped_Droplets", 'zip', "Cropped_Droplets")

# Step 2: Download the zip file
files.download("Cropped_Droplets.zip")

"""CNN with manual splitting"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, r2_score

# ============================
# Dataset Definition
# ============================
class DropletDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.labels_df = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx):
        row = self.labels_df.iloc[idx]
        img_path = os.path.join(self.root_dir, row['Filename'])
        image = Image.open(img_path).convert("L")  # grayscale
        if self.transform:
            image = self.transform(image)
        label = np.log1p(row['Percent_Dead'] / 100.0)
        return image, torch.tensor(label, dtype=torch.float32)

# ============================
# Transforms
# ============================
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])  # grayscale
])

# === Update these paths to your own ===
train_csv = "/content/drive/MyDrive/Colab Notebooks/train/train_labels.csv"
train_root = "/content/drive/MyDrive/Colab Notebooks/train"
val_csv = "/content/drive/MyDrive/Colab Notebooks/val/val_labels.csv"
val_root = "/content/drive/MyDrive/Colab Notebooks/val"

train_dataset = DropletDataset(train_csv, train_root, transform=transform)
val_dataset = DropletDataset(val_csv, val_root, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

# ============================
# Tuned CNN Model
# ============================
class TunedCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((4, 4)),
            nn.Flatten()
        )
        self.fc = nn.Sequential(
            nn.Linear(64 * 4 * 4, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 1)
        )

    def forward(self, x):
        x = self.cnn(x)
        return self.fc(x).squeeze(1)

# ============================
# Training Setup
# ============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = TunedCNN().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
loss_fn = nn.HuberLoss()

train_losses, val_losses = [], []
best_loss = float('inf')
patience = 10
trigger = 0
num_epochs = 100

# ============================
# Training Loop
# ============================
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        preds = model(imgs)
        loss = loss_fn(preds, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_train_loss = total_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    model.eval()
    val_loss = 0
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            preds = model(imgs)
            val_loss += loss_fn(preds, labels).item()

    avg_val_loss = val_loss / len(val_loader)
    val_losses.append(avg_val_loss)
    print(f"Epoch {epoch+1:03d} - Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}")

    if avg_val_loss < best_loss:
        best_loss = avg_val_loss
        trigger = 0
        torch.save(model.state_dict(), "best_tuned_cnn.pth")
    else:
        trigger += 1
        if trigger >= patience:
            print("Early stopping triggered.")
            break

# ============================
# Plot Loss
# ============================
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.title("Tuned CNN Training & Validation Loss")
plt.grid(True)
plt.show()

# ============================
# Evaluate
# ============================
model.load_state_dict(torch.load("best_tuned_cnn.pth"))
model.eval()
true_vals, pred_vals = [], []

with torch.no_grad():
    for imgs, labels in val_loader:
        imgs = imgs.to(device)
        preds = model(imgs).cpu().numpy()
        labels = labels.cpu().numpy()
        preds_rescaled = np.clip(np.expm1(preds) * 100, 0, 100)
        labels_rescaled = np.expm1(labels) * 100
        pred_vals.extend(preds_rescaled)
        true_vals.extend(labels_rescaled)

mae = mean_absolute_error(true_vals, pred_vals)
r2 = r2_score(true_vals, pred_vals)
print(f"\nFinal MAE: {mae:.4f} | R²: {r2:.4f}")

# ============================
# Scatter Plot
# ============================
plt.figure(figsize=(6,6))
plt.scatter(true_vals, pred_vals, alpha=0.6)
plt.plot([0, max(true_vals)], [0, max(true_vals)], 'r--')
plt.xlabel("True % Dead")
plt.ylabel("Predicted % Dead")
plt.title("Tuned CNN Prediction vs Actual")
plt.grid(True)
plt.show()

"""ViT with manual splitting

"""

# ========================
# 1. Imports
# ========================
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from timm import create_model
from PIL import Image
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, r2_score

# ========================
# 2. Dataset Definition
# ========================
class DropletDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.labels_df = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx):
        row = self.labels_df.iloc[idx]
        img_path = os.path.join(self.root_dir, row['Filename'])
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        label = np.log1p(row['Percent_Dead'] / 100.0)
        return image, torch.tensor(label, dtype=torch.float32)

# ========================
# 3. Transform & DataLoader
# ========================
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

train_dataset = DropletDataset(
    csv_file="/content/drive/MyDrive/Colab Notebooks/train/train_labels.csv",
    root_dir="/content/drive/MyDrive/Colab Notebooks/train",
    transform=transform
)

val_dataset = DropletDataset(
    csv_file="/content/drive/MyDrive/Colab Notebooks/val/val_labels.csv",
    root_dir="/content/drive/MyDrive/Colab Notebooks/val",
    transform=transform
)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

# ========================
# 4. Vision Transformer Model
# ========================
class ViTRegressor(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = create_model("vit_base_patch16_224", pretrained=True)
        self.backbone.head = nn.Linear(self.backbone.head.in_features, 1)

    def forward(self, x):
        return self.backbone(x).squeeze(1)

# ========================
# 5. Training Setup
# ========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ViTRegressor().to(device)
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
loss_fn = nn.HuberLoss()
num_epochs = 100
best_loss = float('inf')
patience = 10
trigger = 0
train_losses, val_losses = [], []

# ========================
# 6. Training Loop
# ========================
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        preds = model(imgs)
        loss = loss_fn(preds, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_train_loss = total_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    model.eval()
    val_loss = 0
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            preds = model(imgs)
            val_loss += loss_fn(preds, labels).item()
    avg_val_loss = val_loss / len(val_loader)
    val_losses.append(avg_val_loss)

    print(f"Epoch {epoch+1:03d} - Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}")
    if avg_val_loss < best_loss:
        best_loss = avg_val_loss
        trigger = 0
        torch.save(model.state_dict(), "best_vit_model.pth")
    else:
        trigger += 1
        if trigger >= patience:
            print("Early stopping triggered.")
            break

# ========================
# 7. Loss Curve
# ========================
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.title("ViT Training & Validation Loss")
plt.grid(True)
plt.show()

# ========================
# 8. Evaluation
# ========================
model.load_state_dict(torch.load("best_vit_model.pth"))
model.eval()

true_vals, pred_vals = [], []
with torch.no_grad():
    for imgs, labels in val_loader:
        imgs = imgs.to(device)
        preds = model(imgs).cpu().numpy()
        labels = labels.cpu().numpy()
        preds_rescaled = np.clip(np.expm1(preds) * 100, 0, 100)
        labels_rescaled = np.expm1(labels) * 100
        pred_vals.extend(preds_rescaled)
        true_vals.extend(labels_rescaled)

mae = mean_absolute_error(true_vals, pred_vals)
r2 = r2_score(true_vals, pred_vals)
print(f"\nFinal MAE: {mae:.4f} | R²: {r2:.4f}")

# ========================
# 9. Scatter Plot
# ========================
plt.figure(figsize=(6,6))
plt.scatter(true_vals, pred_vals, alpha=0.6)
plt.plot([0, max(true_vals)], [0, max(true_vals)], 'r--')
plt.xlabel("True % Dead")
plt.ylabel("Predicted % Dead")
plt.title("Prediction vs. Actual Viability (ViT)")
plt.grid(True)
plt.show()

"""Code to run the test data set"""

import torch
import torch.nn as nn
from torchvision import transforms
from timm import create_model
from PIL import Image
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, r2_score

# ============================
# Config
# ============================
test_csv = "/content/drive/MyDrive/Colab Notebooks/test/test_labels.csv"
test_img_dir = "/content/drive/MyDrive/Colab Notebooks/test"
model_path = "best_vit_model.pth"

# ============================
# Test Dataset Definition
# ============================
class DropletTestDataset(torch.utils.data.Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.labels_df = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx):
        row = self.labels_df.iloc[idx]
        img_path = os.path.join(self.root_dir, row[0])
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        label = np.log1p(row[1] / 100.0)  # log scale
        return image, torch.tensor(label, dtype=torch.float32), row[0]

# ============================
# Transform
# ============================
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# ============================
# Load Dataset
# ============================
test_dataset = DropletTestDataset(
    csv_file=test_csv,
    root_dir=test_img_dir,
    transform=transform
)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)

# ============================
# Load Model
# ============================
class ViTRegressor(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = create_model("vit_base_patch16_224", pretrained=False)
        self.backbone.head = nn.Linear(self.backbone.head.in_features, 1)

    def forward(self, x):
        return self.backbone(x).squeeze(1)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = ViTRegressor().to(device)
model.load_state_dict(torch.load(model_path))
model.eval()

# ============================
# Inference and Metrics
# ============================
true_vals, pred_vals, filenames = [], [], []

with torch.no_grad():
    for imgs, labels, names in test_loader:
        imgs = imgs.to(device)
        preds = model(imgs).cpu().numpy()
        labels = labels.cpu().numpy()

        # Convert from log scale
        preds_rescaled = np.clip(np.expm1(preds) * 100, 0, 100)
        labels_rescaled = np.expm1(labels) * 100

        pred_vals.extend(preds_rescaled)
        true_vals.extend(labels_rescaled)
        filenames.extend(names)

# ============================
# Evaluation Results
# ============================
mae = mean_absolute_error(true_vals, pred_vals)
r2 = r2_score(true_vals, pred_vals)
print(f"\n📊 Test Set Performance - MAE: {mae:.4f} | R²: {r2:.4f}")

# ============================
# Save Results (Optional)
# ============================
results_df = pd.DataFrame({
    "Filename": filenames,
    "True_%Dead": true_vals,
    "Predicted_%Dead": pred_vals
})
results_df.to_csv("vit_test_predictions.csv", index=False)

# ============================
# Plot
# ============================
plt.figure(figsize=(6,6))
plt.scatter(true_vals, pred_vals, alpha=0.6)
plt.plot([0, max(true_vals)], [0, max(true_vals)], 'r--')
plt.xlabel("True % Dead")
plt.ylabel("Predicted % Dead")
plt.title("ViT Model: Prediction vs. Actual on Test Set")
plt.grid(True)
plt.tight_layout()
plt.show()